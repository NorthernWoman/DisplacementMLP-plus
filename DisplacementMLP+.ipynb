{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NorthernWoman/DisplacementMLP-plus/blob/main/DisplacementMLP%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OBVFijMPIkpi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "06a68675-d408-4266-fad2-8379d400a4a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'guards' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2039001522.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0mloss00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0mz05\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"decoupled_weight_decay\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecoupled_weight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         }\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# We can safely turn off functools.wraps here because the inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maot_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCompileArtifacts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0msignature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbytecode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36mCompileArtifacts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msignature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbytecode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mguard_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGuardManagerWrapper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mguards_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mimport_sources\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'guards' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
        "import numpy as np\n",
        "import skimage\n",
        "import skimage\n",
        "from skimage import io\n",
        "import time\n",
        "from conv_layers import *\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "#\n",
        "# This code refers to the implementation of DisplacementMLP+ described in the paper:\n",
        "# D. Mangileva et. al. DisplacementMLP+: Unsupervised Neural Network for Dynamic Scene Analysis, 2025\n",
        "\n",
        "###\n",
        "# setting the size of the small coordinate grid (60x60)\n",
        "st = 60\n",
        "st0 = int(st/2)\n",
        "st00 = int(240/st)\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "def np_to_torch(img_np):\n",
        "    return torch.from_numpy(img_np)[None, :]\n",
        "###\n",
        "# Sinelayer implementation, taken from the work:\n",
        "# Sitzmann V. et al. Implicit neural representations with periodic activation functions, 2020\n",
        "\n",
        "class SineLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 is_first=False, omega_0=30,need_sigmoid = True, need_tanh = False):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Conv2d(in_features, out_features, bias=bias, kernel_size = 1, padding = 0)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.sin(self.omega_0 * self.linear(input))\n",
        "\n",
        "    def forward_with_intermediate(self, input):\n",
        "\n",
        "        intermediate = self.omega_0 * self.linear(input)\n",
        "        return torch.sin(intermediate), intermediate\n",
        "\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
        "                 first_omega_0=30, hidden_omega_0=30, need_sigmoid = True, need_tanh = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = []\n",
        "        self.net.append(SineLayer(in_features, hidden_features,\n",
        "                                  is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Conv2d(hidden_features, out_features, kernel_size = 1, padding = 0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
        "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(hidden_features, out_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "        if need_sigmoid:\n",
        "            self.net.append(nn.Sigmoid())\n",
        "        elif need_tanh:\n",
        "            self.net.append(nn.Tanh())\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        output = self.net(coords)\n",
        "        return output, coords\n",
        "\n",
        "    def forward_with_activations(self, coords, retain_grad=False):\n",
        "        activations = OrderedDict()\n",
        "        activation_count = 0\n",
        "        x = coords.clone().detach().requires_grad_(True)\n",
        "        activations['input'] = x\n",
        "        for i, layer in enumerate(self.net):\n",
        "            if isinstance(layer, SineLayer):\n",
        "                x, intermed = layer.forward_with_intermediate(x)\n",
        "\n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    intermed.retain_grad()\n",
        "\n",
        "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
        "                activation_count += 1\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "\n",
        "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
        "            activation_count += 1\n",
        "\n",
        "        return activations\n",
        "###\n",
        "# link to the folder number where the pair of consecutive images is located\n",
        "#n = int(sys.argv[1]) - 1\n",
        "###\n",
        "# creating a large coordinate grid (size (240,240,2))\n",
        "xy_grid_batch2 = []\n",
        "coords_x2 = np.linspace(-1, 1, 240)\n",
        "coords_y2 = np.linspace(-1, 1, 240)\n",
        "xy_grid2 = np.stack(np.meshgrid(coords_x2, coords_y2), -1)\n",
        "xy_grid_var2 = np_to_torch(xy_grid2.transpose(2,0,1)).type(dtype).cuda()\n",
        "xy_grid_batch_var2 = xy_grid_var2.repeat(1, 1, 1, 1)\n",
        "grid_input_single_gd2 = xy_grid_var2.detach().clone()\n",
        "model_input2 = grid_input_single_gd2\n",
        "###\n",
        "# creating a small coordinate grid (size (60,60,2))\n",
        "xy_grid_batch = []\n",
        "coords_x = np.linspace(-1, 1, st)\n",
        "coords_y = np.linspace(-1, 1, st)\n",
        "xy_grid = np.stack(np.meshgrid(coords_x, coords_y), -1)\n",
        "xy_grid_var = np_to_torch(xy_grid.transpose(2,0,1)).type(dtype).cuda()\n",
        "xy_grid_batch_var = xy_grid_var.repeat(1, 1, 1, 1)\n",
        "grid_input_single_gd = xy_grid_var.detach().clone()\n",
        "model_input = grid_input_single_gd\n",
        "###\n",
        "#reading images\n",
        "image0 = io.imread('./0.png')\n",
        "image1 = io.imread('./1.png')\n",
        "image = image0\n",
        "images_warp_np = np.array(image).reshape(-1,240,240)\n",
        "images_warp_np = np.array(images_warp_np/255,dtype = np.float32)\n",
        "img_gt_batch_var = torch.from_numpy(images_warp_np).type(dtype).cuda()\n",
        "ground_truth = img_gt_batch_var\n",
        "\n",
        "image = image1\n",
        "images_warp_np1 = np.array(image1).reshape(-1,240,240)\n",
        "images_warp_np1 = np.array(images_warp_np1/255,dtype = np.float32)\n",
        "\n",
        "img_gt_batch_var1 = torch.from_numpy(images_warp_np1).type(dtype).cuda()\n",
        "ground_truth1 = img_gt_batch_var1\n",
        "###\n",
        "# creating MLP image generator\n",
        "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda()\n",
        "\n",
        "###\n",
        "# create a set of MLP image generators\n",
        "models = [[] for i in range(st00)]\n",
        "for v1 in range(st00):\n",
        "    for v2 in range(st00):\n",
        "        models[v1].append(Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda())\n",
        "\n",
        "###\n",
        "# creating a set of model parameters\n",
        "models = np.array(models)\n",
        "model_params_list = [{'params':img_siren.parameters()}]\n",
        "for v1 in range(st00):\n",
        "    for v2 in range(st00):\n",
        "        model_params_list.append({'params':models[v1,v2].parameters()})\n",
        "###\n",
        "# training of the image generator according to the novel proposed scheme\n",
        "loss00 = []\n",
        "total_steps = 3001\n",
        "optim = torch.optim.Adam(lr=1e-4, params=model_params_list)\n",
        "z05 = torch.zeros_like(ground_truth).cuda()\n",
        "for step in range(total_steps):\n",
        "    z00 = torch.zeros_like(ground_truth).cuda()\n",
        "    z01 = torch.zeros_like(ground_truth).cuda()\n",
        "    for v1, i in enumerate(range(st0,240,st)):\n",
        "        for v2, j in enumerate(range(st0,240,st)):\n",
        "            images_warp_np = np.array(image[i-st0:i+st0,j-st0:j+st0]).reshape(-1,st,st)\n",
        "            images_warp_np = np.array(images_warp_np/255,dtype = np.float32)\n",
        "            img_gt_batch_var = torch.from_numpy(images_warp_np).type(dtype).cuda()\n",
        "            ground_truth0 = img_gt_batch_var\n",
        "            img_siren2 = models[v1,v2]\n",
        "\n",
        "            model_output, h = img_siren2(model_input)\n",
        "            z00[:,i-st0:i+st0,j-st0:j+st0] = model_output[0]\n",
        "\n",
        "            model_output, h = img_siren(model_input2[:,:,i-st0:i+st0,j-st0:j+st0])\n",
        "            z01[:,i-st0:i+st0,j-st0:j+st0] = model_output[0]\n",
        "    loss = torch.nn.functional.l1_loss(z00,ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(z00,ground_truth)\n",
        "    loss += torch.nn.functional.l1_loss(z01,z00)\n",
        "    loss += torch.nn.functional.mse_loss(z01,z00)\n",
        "    loss += torch.nn.functional.l1_loss(z01,ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(z01,ground_truth)\n",
        "    loss0 = torch.nn.functional.l1_loss(z01,ground_truth)\n",
        "    loss0 += torch.nn.functional.mse_loss(z01,ground_truth)\n",
        "\n",
        "    if step % 25 == 0:\n",
        "\n",
        "\n",
        "        print('Epoch %d, loss = %.06f' % (step, float(loss0)))\n",
        "        loss00.append(round(float(loss0),6))\n",
        "\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "model_params_list.append({'params':img_siren.parameters()})\n",
        "total_steps = 301\n",
        "for step in range(total_steps):\n",
        "\n",
        "    model_output2, h = img_siren(model_input2)\n",
        "    loss = torch.nn.functional.l1_loss(model_output2[0],ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(model_output2[0],ground_truth)\n",
        "\n",
        "    if step % 25 == 0:\n",
        "\n",
        "        print('Epoch %d, loss = %.06f' % (step, float(loss)))\n",
        "        loss00.append(round(float(loss),6))\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "loss00 = np.array(loss00)\n",
        "\n",
        "np.save('./loss_new_0_60_0.npy'.format(n = n), loss00)\n",
        "torch.save(img_siren.state_dict(), './best-model-img00.pt'.format(n = n))\n",
        "\n",
        "###\n",
        "\n",
        "# loading pre-trained MLP images generator with the best parameters obtained in the previous step\n",
        "\n",
        "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda()\n",
        "img_siren.load_state_dict(torch.load('./best-model-img00.pt'.format(n = n)))\n",
        "img_siren.eval()\n",
        "###\n",
        "# load pre-trained MLP grid generator with initialized weights\n",
        "img_grid = conv_layers(2,2, num_hidden = 256, need_sigmoid = False, need_tanh = True)\n",
        "img_grid.cuda()\n",
        "img_grid.load_state_dict(torch.load('./best-model-grid02.pt'))\n",
        "img_grid.eval()\n",
        "###\n",
        "\n",
        "# creating a set of model parameters\n",
        "model_params_list = [{'params':img_grid.parameters()}]\n",
        "\n",
        "# training of MLP grid generator to compute xy displacement field\n",
        "\n",
        "optim = torch.optim.Adam(model_params_list, lr=1e-4)\n",
        "total_steps = 5001\n",
        "grid = []\n",
        "losses = []\n",
        "loss00 = []\n",
        "for step in range(total_steps):\n",
        "    h0 = img_grid(model_input2)\n",
        "    h1 = h0 + torch.randn_like(h0)*0.0005\n",
        "    h3 = 1.1*torch.cat([h0])\n",
        "    grid_output0 = 1.1*torch.cat([h1])\n",
        "    model_output0,w= img_siren(grid_output0)\n",
        "    loss = torch.nn.functional.l1_loss(model_output0[0][:,18:221,18:221],ground_truth1[:,18:221,18:221])\n",
        "    loss += torch.nn.functional.mse_loss(model_output0[0][:,18:221,18:221],ground_truth1[:,18:221,18:221])\n",
        "    if step % 25 == 0:\n",
        "        print('Epoch %d, loss = %.09f' % (step, float(loss)))\n",
        "        loss00.append(round(float(loss),6))\n",
        "    grid.append(h3)\n",
        "    losses.append(round(float(loss),9))\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "loss00 = np.array(loss00)\n",
        "np.save('./loss_new_1_60_0.npy', loss00)\n",
        "###\n",
        "\n",
        "\n",
        "# convert and save displasement field to file new_60_0.npy\n",
        "ind = losses.index(min(losses))\n",
        "torch.save(grid[ind],'./{n}/tensor.pt'.format(n = n))\n",
        "refined_xy = torch.load('./{n}/tensor.pt'.format(n = n))\n",
        "z00 = torch.zeros(1,2,240,240).cuda()\n",
        "refined_warp = (refined_xy - xy_grid_batch_var2)\n",
        "\n",
        "refined_uv = torch.cat(((240 - 1.0)*refined_warp[:, 0:1, :, :]/2 , (240 - 1.0)*refined_warp[:, 1:2, :, :]/2), 1)\n",
        "\n",
        "warp_img = refined_uv[0].detach().cpu().numpy().transpose(1,2,0)\n",
        "z = np.zeros(shape = (240,240,2))\n",
        "\n",
        "np.save('./new_60_0.npy', warp_img)\n",
        "###\n",
        "plt.imshow(z[:,:,0])\n",
        "plt.show()\n"
      ]
    }
  ]
}