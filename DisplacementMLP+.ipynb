{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NorthernWoman/DisplacementMLP-plus/blob/main/DisplacementMLP%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OBVFijMPIkpi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c15af01-91d6-4db5-cd5f-a0d9a117ca1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss = 0.327615\n",
            "Epoch 25, loss = 0.053898\n",
            "Epoch 50, loss = 0.034889\n",
            "Epoch 75, loss = 0.027740\n",
            "Epoch 100, loss = 0.022920\n",
            "Epoch 125, loss = 0.018935\n",
            "Epoch 150, loss = 0.016731\n",
            "Epoch 175, loss = 0.013870\n",
            "Epoch 200, loss = 0.012205\n",
            "Epoch 225, loss = 0.010749\n",
            "Epoch 250, loss = 0.009748\n",
            "Epoch 275, loss = 0.008681\n",
            "Epoch 300, loss = 0.007809\n",
            "Epoch 325, loss = 0.007042\n",
            "Epoch 350, loss = 0.006599\n",
            "Epoch 375, loss = 0.006566\n",
            "Epoch 400, loss = 0.005736\n",
            "Epoch 425, loss = 0.005388\n",
            "Epoch 450, loss = 0.005315\n",
            "Epoch 475, loss = 0.005030\n",
            "Epoch 500, loss = 0.004720\n",
            "Epoch 525, loss = 0.004385\n",
            "Epoch 550, loss = 0.004240\n",
            "Epoch 575, loss = 0.004233\n",
            "Epoch 600, loss = 0.004043\n",
            "Epoch 625, loss = 0.004150\n",
            "Epoch 650, loss = 0.003612\n",
            "Epoch 675, loss = 0.003555\n",
            "Epoch 700, loss = 0.003694\n",
            "Epoch 725, loss = 0.003348\n",
            "Epoch 750, loss = 0.003251\n",
            "Epoch 775, loss = 0.003235\n",
            "Epoch 800, loss = 0.003137\n",
            "Epoch 825, loss = 0.003271\n",
            "Epoch 850, loss = 0.002999\n",
            "Epoch 875, loss = 0.003047\n",
            "Epoch 900, loss = 0.002858\n",
            "Epoch 925, loss = 0.003068\n",
            "Epoch 950, loss = 0.002816\n",
            "Epoch 975, loss = 0.002711\n",
            "Epoch 1000, loss = 0.002918\n",
            "Epoch 1025, loss = 0.002727\n",
            "Epoch 1050, loss = 0.002775\n",
            "Epoch 1075, loss = 0.002668\n",
            "Epoch 1100, loss = 0.002580\n",
            "Epoch 1125, loss = 0.002445\n",
            "Epoch 1150, loss = 0.002473\n",
            "Epoch 1175, loss = 0.002464\n",
            "Epoch 1200, loss = 0.002472\n",
            "Epoch 1225, loss = 0.002458\n",
            "Epoch 1250, loss = 0.002304\n",
            "Epoch 1275, loss = 0.002255\n",
            "Epoch 1300, loss = 0.002244\n",
            "Epoch 1325, loss = 0.002219\n",
            "Epoch 1350, loss = 0.002254\n",
            "Epoch 1375, loss = 0.002187\n",
            "Epoch 1400, loss = 0.002214\n",
            "Epoch 1425, loss = 0.002089\n",
            "Epoch 1450, loss = 0.002125\n",
            "Epoch 1475, loss = 0.002104\n",
            "Epoch 1500, loss = 0.002140\n",
            "Epoch 1525, loss = 0.002073\n",
            "Epoch 1550, loss = 0.001985\n",
            "Epoch 1575, loss = 0.002072\n",
            "Epoch 1600, loss = 0.001890\n",
            "Epoch 1625, loss = 0.002049\n",
            "Epoch 1650, loss = 0.001907\n",
            "Epoch 1675, loss = 0.001852\n",
            "Epoch 1700, loss = 0.001841\n",
            "Epoch 1725, loss = 0.001791\n",
            "Epoch 1750, loss = 0.001872\n",
            "Epoch 1775, loss = 0.001864\n",
            "Epoch 1800, loss = 0.001784\n",
            "Epoch 1825, loss = 0.001739\n",
            "Epoch 1850, loss = 0.001938\n",
            "Epoch 1875, loss = 0.001665\n",
            "Epoch 1900, loss = 0.001730\n",
            "Epoch 1925, loss = 0.001801\n",
            "Epoch 1950, loss = 0.001654\n",
            "Epoch 1975, loss = 0.001725\n",
            "Epoch 2000, loss = 0.001731\n",
            "Epoch 2025, loss = 0.001735\n",
            "Epoch 2050, loss = 0.001572\n",
            "Epoch 2075, loss = 0.001564\n",
            "Epoch 2100, loss = 0.001621\n",
            "Epoch 2125, loss = 0.001569\n",
            "Epoch 2150, loss = 0.001644\n",
            "Epoch 2175, loss = 0.001565\n",
            "Epoch 2200, loss = 0.001563\n",
            "Epoch 2225, loss = 0.001602\n",
            "Epoch 2250, loss = 0.001648\n",
            "Epoch 2275, loss = 0.001461\n",
            "Epoch 2300, loss = 0.001505\n",
            "Epoch 2325, loss = 0.001584\n",
            "Epoch 2350, loss = 0.001467\n",
            "Epoch 2375, loss = 0.001455\n",
            "Epoch 2400, loss = 0.001613\n",
            "Epoch 2425, loss = 0.001489\n",
            "Epoch 2450, loss = 0.001448\n",
            "Epoch 2475, loss = 0.001443\n",
            "Epoch 2500, loss = 0.001401\n",
            "Epoch 2525, loss = 0.001551\n",
            "Epoch 2550, loss = 0.001439\n",
            "Epoch 2575, loss = 0.001520\n",
            "Epoch 2600, loss = 0.001495\n",
            "Epoch 2625, loss = 0.001510\n",
            "Epoch 2650, loss = 0.001515\n",
            "Epoch 2675, loss = 0.001445\n",
            "Epoch 2700, loss = 0.001330\n",
            "Epoch 2725, loss = 0.001499\n",
            "Epoch 2750, loss = 0.001298\n",
            "Epoch 2775, loss = 0.001343\n",
            "Epoch 2800, loss = 0.001478\n",
            "Epoch 2825, loss = 0.001428\n",
            "Epoch 2850, loss = 0.001342\n",
            "Epoch 2875, loss = 0.001490\n",
            "Epoch 2900, loss = 0.001503\n",
            "Epoch 2925, loss = 0.001489\n",
            "Epoch 2950, loss = 0.001372\n",
            "Epoch 2975, loss = 0.001331\n",
            "Epoch 3000, loss = 0.001410\n",
            "Epoch 0, loss = 0.001323\n",
            "Epoch 25, loss = 0.000823\n",
            "Epoch 50, loss = 0.000772\n",
            "Epoch 75, loss = 0.000767\n",
            "Epoch 100, loss = 0.000766\n",
            "Epoch 125, loss = 0.000778\n",
            "Epoch 150, loss = 0.000768\n",
            "Epoch 175, loss = 0.000788\n",
            "Epoch 200, loss = 0.000809\n",
            "Epoch 225, loss = 0.000801\n",
            "Epoch 250, loss = 0.000799\n",
            "Epoch 275, loss = 0.000799\n",
            "Epoch 300, loss = 0.000817\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'n' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2039001522.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0mloss00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss00\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./loss_new_0_60_0.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss00\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_siren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./best-model-img00.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
        "import numpy as np\n",
        "import skimage\n",
        "import skimage\n",
        "from skimage import io\n",
        "import time\n",
        "from conv_layers import *\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "#\n",
        "# This code refers to the implementation of DisplacementMLP+ described in the paper:\n",
        "# D. Mangileva et. al. DisplacementMLP+: Unsupervised Neural Network for Dynamic Scene Analysis, 2025\n",
        "\n",
        "###\n",
        "# setting the size of the small coordinate grid (60x60)\n",
        "st = 60\n",
        "st0 = int(st/2)\n",
        "st00 = int(240/st)\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "def np_to_torch(img_np):\n",
        "    return torch.from_numpy(img_np)[None, :]\n",
        "###\n",
        "# Sinelayer implementation, taken from the work:\n",
        "# Sitzmann V. et al. Implicit neural representations with periodic activation functions, 2020\n",
        "\n",
        "class SineLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 is_first=False, omega_0=30,need_sigmoid = True, need_tanh = False):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Conv2d(in_features, out_features, bias=bias, kernel_size = 1, padding = 0)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.sin(self.omega_0 * self.linear(input))\n",
        "\n",
        "    def forward_with_intermediate(self, input):\n",
        "\n",
        "        intermediate = self.omega_0 * self.linear(input)\n",
        "        return torch.sin(intermediate), intermediate\n",
        "\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
        "                 first_omega_0=30, hidden_omega_0=30, need_sigmoid = True, need_tanh = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = []\n",
        "        self.net.append(SineLayer(in_features, hidden_features,\n",
        "                                  is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Conv2d(hidden_features, out_features, kernel_size = 1, padding = 0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
        "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(hidden_features, out_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "        if need_sigmoid:\n",
        "            self.net.append(nn.Sigmoid())\n",
        "        elif need_tanh:\n",
        "            self.net.append(nn.Tanh())\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        output = self.net(coords)\n",
        "        return output, coords\n",
        "\n",
        "    def forward_with_activations(self, coords, retain_grad=False):\n",
        "        activations = OrderedDict()\n",
        "        activation_count = 0\n",
        "        x = coords.clone().detach().requires_grad_(True)\n",
        "        activations['input'] = x\n",
        "        for i, layer in enumerate(self.net):\n",
        "            if isinstance(layer, SineLayer):\n",
        "                x, intermed = layer.forward_with_intermediate(x)\n",
        "\n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    intermed.retain_grad()\n",
        "\n",
        "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
        "                activation_count += 1\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "\n",
        "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
        "            activation_count += 1\n",
        "\n",
        "        return activations\n",
        "###\n",
        "# link to the folder number where the pair of consecutive images is located\n",
        "#n = int(sys.argv[1]) - 1\n",
        "###\n",
        "# creating a large coordinate grid (size (240,240,2))\n",
        "xy_grid_batch2 = []\n",
        "coords_x2 = np.linspace(-1, 1, 240)\n",
        "coords_y2 = np.linspace(-1, 1, 240)\n",
        "xy_grid2 = np.stack(np.meshgrid(coords_x2, coords_y2), -1)\n",
        "xy_grid_var2 = np_to_torch(xy_grid2.transpose(2,0,1)).type(dtype).cuda()\n",
        "xy_grid_batch_var2 = xy_grid_var2.repeat(1, 1, 1, 1)\n",
        "grid_input_single_gd2 = xy_grid_var2.detach().clone()\n",
        "model_input2 = grid_input_single_gd2\n",
        "###\n",
        "# creating a small coordinate grid (size (60,60,2))\n",
        "xy_grid_batch = []\n",
        "coords_x = np.linspace(-1, 1, st)\n",
        "coords_y = np.linspace(-1, 1, st)\n",
        "xy_grid = np.stack(np.meshgrid(coords_x, coords_y), -1)\n",
        "xy_grid_var = np_to_torch(xy_grid.transpose(2,0,1)).type(dtype).cuda()\n",
        "xy_grid_batch_var = xy_grid_var.repeat(1, 1, 1, 1)\n",
        "grid_input_single_gd = xy_grid_var.detach().clone()\n",
        "model_input = grid_input_single_gd\n",
        "###\n",
        "#reading images\n",
        "image0 = io.imread('./0.png')\n",
        "image1 = io.imread('./1.png')\n",
        "image = image0\n",
        "images_warp_np = np.array(image).reshape(-1,240,240)\n",
        "images_warp_np = np.array(images_warp_np/255,dtype = np.float32)\n",
        "img_gt_batch_var = torch.from_numpy(images_warp_np).type(dtype).cuda()\n",
        "ground_truth = img_gt_batch_var\n",
        "\n",
        "image = image1\n",
        "images_warp_np1 = np.array(image1).reshape(-1,240,240)\n",
        "images_warp_np1 = np.array(images_warp_np1/255,dtype = np.float32)\n",
        "\n",
        "img_gt_batch_var1 = torch.from_numpy(images_warp_np1).type(dtype).cuda()\n",
        "ground_truth1 = img_gt_batch_var1\n",
        "###\n",
        "# creating MLP image generator\n",
        "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda()\n",
        "\n",
        "###\n",
        "# create a set of MLP image generators\n",
        "models = [[] for i in range(st00)]\n",
        "for v1 in range(st00):\n",
        "    for v2 in range(st00):\n",
        "        models[v1].append(Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda())\n",
        "\n",
        "###\n",
        "# creating a set of model parameters\n",
        "models = np.array(models)\n",
        "model_params_list = [{'params':img_siren.parameters()}]\n",
        "for v1 in range(st00):\n",
        "    for v2 in range(st00):\n",
        "        model_params_list.append({'params':models[v1,v2].parameters()})\n",
        "###\n",
        "# training of the image generator according to the novel proposed scheme\n",
        "loss00 = []\n",
        "total_steps = 3001\n",
        "optim = torch.optim.Adam(lr=1e-4, params=model_params_list)\n",
        "z05 = torch.zeros_like(ground_truth).cuda()\n",
        "for step in range(total_steps):\n",
        "    z00 = torch.zeros_like(ground_truth).cuda()\n",
        "    z01 = torch.zeros_like(ground_truth).cuda()\n",
        "    for v1, i in enumerate(range(st0,240,st)):\n",
        "        for v2, j in enumerate(range(st0,240,st)):\n",
        "            images_warp_np = np.array(image[i-st0:i+st0,j-st0:j+st0]).reshape(-1,st,st)\n",
        "            images_warp_np = np.array(images_warp_np/255,dtype = np.float32)\n",
        "            img_gt_batch_var = torch.from_numpy(images_warp_np).type(dtype).cuda()\n",
        "            ground_truth0 = img_gt_batch_var\n",
        "            img_siren2 = models[v1,v2]\n",
        "\n",
        "            model_output, h = img_siren2(model_input)\n",
        "            z00[:,i-st0:i+st0,j-st0:j+st0] = model_output[0]\n",
        "\n",
        "            model_output, h = img_siren(model_input2[:,:,i-st0:i+st0,j-st0:j+st0])\n",
        "            z01[:,i-st0:i+st0,j-st0:j+st0] = model_output[0]\n",
        "    loss = torch.nn.functional.l1_loss(z00,ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(z00,ground_truth)\n",
        "    loss += torch.nn.functional.l1_loss(z01,z00)\n",
        "    loss += torch.nn.functional.mse_loss(z01,z00)\n",
        "    loss += torch.nn.functional.l1_loss(z01,ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(z01,ground_truth)\n",
        "    loss0 = torch.nn.functional.l1_loss(z01,ground_truth)\n",
        "    loss0 += torch.nn.functional.mse_loss(z01,ground_truth)\n",
        "\n",
        "    if step % 25 == 0:\n",
        "\n",
        "\n",
        "        print('Epoch %d, loss = %.06f' % (step, float(loss0)))\n",
        "        loss00.append(round(float(loss0),6))\n",
        "\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "model_params_list.append({'params':img_siren.parameters()})\n",
        "total_steps = 301\n",
        "for step in range(total_steps):\n",
        "\n",
        "    model_output2, h = img_siren(model_input2)\n",
        "    loss = torch.nn.functional.l1_loss(model_output2[0],ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(model_output2[0],ground_truth)\n",
        "\n",
        "    if step % 25 == 0:\n",
        "\n",
        "        print('Epoch %d, loss = %.06f' % (step, float(loss)))\n",
        "        loss00.append(round(float(loss),6))\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "loss00 = np.array(loss00)\n",
        "\n",
        "np.save('./loss_new_0_60_0.npy'.format(n = n), loss00)\n",
        "torch.save(img_siren.state_dict(), './best-model-img00.pt'.format(n = n))\n",
        "\n",
        "###\n",
        "\n",
        "# loading pre-trained MLP images generator with the best parameters obtained in the previous step\n",
        "\n",
        "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda()\n",
        "img_siren.load_state_dict(torch.load('./best-model-img00.pt'.format(n = n)))\n",
        "img_siren.eval()\n",
        "###\n",
        "# load pre-trained MLP grid generator with initialized weights\n",
        "img_grid = conv_layers(2,2, num_hidden = 256, need_sigmoid = False, need_tanh = True)\n",
        "img_grid.cuda()\n",
        "img_grid.load_state_dict(torch.load('./best-model-grid02.pt'))\n",
        "img_grid.eval()\n",
        "###\n",
        "\n",
        "# creating a set of model parameters\n",
        "model_params_list = [{'params':img_grid.parameters()}]\n",
        "\n",
        "# training of MLP grid generator to compute xy displacement field\n",
        "\n",
        "optim = torch.optim.Adam(model_params_list, lr=1e-4)\n",
        "total_steps = 5001\n",
        "grid = []\n",
        "losses = []\n",
        "loss00 = []\n",
        "for step in range(total_steps):\n",
        "    h0 = img_grid(model_input2)\n",
        "    h1 = h0 + torch.randn_like(h0)*0.0005\n",
        "    h3 = 1.1*torch.cat([h0])\n",
        "    grid_output0 = 1.1*torch.cat([h1])\n",
        "    model_output0,w= img_siren(grid_output0)\n",
        "    loss = torch.nn.functional.l1_loss(model_output0[0][:,18:221,18:221],ground_truth1[:,18:221,18:221])\n",
        "    loss += torch.nn.functional.mse_loss(model_output0[0][:,18:221,18:221],ground_truth1[:,18:221,18:221])\n",
        "    if step % 25 == 0:\n",
        "        print('Epoch %d, loss = %.09f' % (step, float(loss)))\n",
        "        loss00.append(round(float(loss),6))\n",
        "    grid.append(h3)\n",
        "    losses.append(round(float(loss),9))\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "loss00 = np.array(loss00)\n",
        "np.save('./loss_new_1_60_0.npy', loss00)\n",
        "###\n",
        "\n",
        "\n",
        "# convert and save displasement field to file new_60_0.npy\n",
        "ind = losses.index(min(losses))\n",
        "torch.save(grid[ind],'./{n}/tensor.pt'.format(n = n))\n",
        "refined_xy = torch.load('./{n}/tensor.pt'.format(n = n))\n",
        "z00 = torch.zeros(1,2,240,240).cuda()\n",
        "refined_warp = (refined_xy - xy_grid_batch_var2)\n",
        "\n",
        "refined_uv = torch.cat(((240 - 1.0)*refined_warp[:, 0:1, :, :]/2 , (240 - 1.0)*refined_warp[:, 1:2, :, :]/2), 1)\n",
        "\n",
        "warp_img = refined_uv[0].detach().cpu().numpy().transpose(1,2,0)\n",
        "z = np.zeros(shape = (240,240,2))\n",
        "\n",
        "np.save('./new_60_0.npy', warp_img)\n",
        "###\n",
        "plt.imshow(z[:,:,0])\n",
        "plt.show()\n"
      ]
    }
  ]
}