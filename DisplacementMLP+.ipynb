{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBVFijMPIkpi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
        "import numpy as np\n",
        "import skimage\n",
        "import skimage\n",
        "from skimage import io\n",
        "import time\n",
        "from networks2.conv_layers import *\n",
        "import sys\n",
        "\n",
        "#\n",
        "# This code refers to the implementation of DisplacementMLP+ described in the paper:\n",
        "# D. Mangileva et. al. DisplacementMLP+: Unsupervised Neural Network for Dynamic Scene Analysis, 2025\n",
        "\n",
        "###\n",
        "# setting the size of the small coordinate grid (60x60)\n",
        "st = 60\n",
        "st0 = int(st/2)\n",
        "st00 = int(240/st)\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "def np_to_torch(img_np):\n",
        "    return torch.from_numpy(img_np)[None, :]\n",
        "###\n",
        "# Sinelayer implementation, taken from the work:\n",
        "# Sitzmann V. et al. Implicit neural representations with periodic activation functions, 2020\n",
        "\n",
        "class SineLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 is_first=False, omega_0=30,need_sigmoid = True, need_tanh = False):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Conv2d(in_features, out_features, bias=bias, kernel_size = 1, padding = 0)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.sin(self.omega_0 * self.linear(input))\n",
        "\n",
        "    def forward_with_intermediate(self, input):\n",
        "\n",
        "        intermediate = self.omega_0 * self.linear(input)\n",
        "        return torch.sin(intermediate), intermediate\n",
        "\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
        "                 first_omega_0=30, hidden_omega_0=30, need_sigmoid = True, need_tanh = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = []\n",
        "        self.net.append(SineLayer(in_features, hidden_features,\n",
        "                                  is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Conv2d(hidden_features, out_features, kernel_size = 1, padding = 0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
        "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(hidden_features, out_features,\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "        if need_sigmoid:\n",
        "            self.net.append(nn.Sigmoid())\n",
        "        elif need_tanh:\n",
        "            self.net.append(nn.Tanh())\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        output = self.net(coords)\n",
        "        return output, coords\n",
        "\n",
        "    def forward_with_activations(self, coords, retain_grad=False):\n",
        "        activations = OrderedDict()\n",
        "        activation_count = 0\n",
        "        x = coords.clone().detach().requires_grad_(True)\n",
        "        activations['input'] = x\n",
        "        for i, layer in enumerate(self.net):\n",
        "            if isinstance(layer, SineLayer):\n",
        "                x, intermed = layer.forward_with_intermediate(x)\n",
        "\n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    intermed.retain_grad()\n",
        "\n",
        "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
        "                activation_count += 1\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "\n",
        "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
        "            activation_count += 1\n",
        "\n",
        "        return activations\n",
        "###\n",
        "# link to the folder number where the pair of consecutive images is located\n",
        "n = int(sys.argv[1]) - 1\n",
        "###\n",
        "# creating a large coordinate grid (size (240,240,2))\n",
        "xy_grid_batch2 = []\n",
        "coords_x2 = np.linspace(-1, 1, 240)\n",
        "coords_y2 = np.linspace(-1, 1, 240)\n",
        "xy_grid2 = np.stack(np.meshgrid(coords_x2, coords_y2), -1)\n",
        "xy_grid_var2 = np_to_torch(xy_grid2.transpose(2,0,1)).type(dtype).cuda()\n",
        "xy_grid_batch_var2 = xy_grid_var2.repeat(1, 1, 1, 1)\n",
        "grid_input_single_gd2 = xy_grid_var2.detach().clone()\n",
        "model_input2 = grid_input_single_gd2\n",
        "###\n",
        "# creating a small coordinate grid (size (60,60,2))\n",
        "xy_grid_batch = []\n",
        "coords_x = np.linspace(-1, 1, st)\n",
        "coords_y = np.linspace(-1, 1, st)\n",
        "xy_grid = np.stack(np.meshgrid(coords_x, coords_y), -1)\n",
        "xy_grid_var = np_to_torch(xy_grid.transpose(2,0,1)).type(dtype).cuda()\n",
        "xy_grid_batch_var = xy_grid_var.repeat(1, 1, 1, 1)\n",
        "grid_input_single_gd = xy_grid_var.detach().clone()\n",
        "model_input = grid_input_single_gd\n",
        "###\n",
        "#reading images\n",
        "image0 = io.imread('./{n}/0.png'.format(n = n))\n",
        "image1 = io.imread('./{n}/1.png'.format(n = n))\n",
        "image = image0\n",
        "images_warp_np = np.array(image).reshape(-1,240,240)\n",
        "images_warp_np = np.array(images_warp_np/255,dtype = np.float32)\n",
        "img_gt_batch_var = torch.from_numpy(images_warp_np).type(dtype).cuda()\n",
        "ground_truth = img_gt_batch_var\n",
        "\n",
        "image = image1\n",
        "images_warp_np1 = np.array(image1).reshape(-1,240,240)\n",
        "images_warp_np1 = np.array(images_warp_np1/255,dtype = np.float32)\n",
        "\n",
        "img_gt_batch_var1 = torch.from_numpy(images_warp_np1).type(dtype).cuda()\n",
        "ground_truth1 = img_gt_batch_var1\n",
        "###\n",
        "# creating MLP image generator\n",
        "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda()\n",
        "\n",
        "###\n",
        "# create a set of MLP image generators\n",
        "models = [[] for i in range(st00)]\n",
        "for v1 in range(st00):\n",
        "    for v2 in range(st00):\n",
        "        models[v1].append(Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda())\n",
        "\n",
        "###\n",
        "# creating a set of model parameters\n",
        "models = np.array(models)\n",
        "model_params_list = [{'params':img_siren.parameters()}]\n",
        "for v1 in range(st00):\n",
        "    for v2 in range(st00):\n",
        "        model_params_list.append({'params':models[v1,v2].parameters()})\n",
        "###\n",
        "# training of the image generator according to the novel proposed scheme\n",
        "loss00 = []\n",
        "total_steps = 3001\n",
        "optim = torch.optim.Adam(lr=1e-4, params=model_params_list)\n",
        "z05 = torch.zeros_like(ground_truth).cuda()\n",
        "for step in range(total_steps):\n",
        "    z00 = torch.zeros_like(ground_truth).cuda()\n",
        "    z01 = torch.zeros_like(ground_truth).cuda()\n",
        "    for v1, i in enumerate(range(st0,240,st)):\n",
        "        for v2, j in enumerate(range(st0,240,st)):\n",
        "            images_warp_np = np.array(image[i-st0:i+st0,j-st0:j+st0]).reshape(-1,st,st)\n",
        "            images_warp_np = np.array(images_warp_np/255,dtype = np.float32)\n",
        "            img_gt_batch_var = torch.from_numpy(images_warp_np).type(dtype).cuda()\n",
        "            ground_truth0 = img_gt_batch_var\n",
        "            img_siren2 = models[v1,v2]\n",
        "\n",
        "            model_output, h = img_siren2(model_input)\n",
        "            z00[:,i-st0:i+st0,j-st0:j+st0] = model_output[0]\n",
        "\n",
        "            model_output, h = img_siren(model_input2[:,:,i-st0:i+st0,j-st0:j+st0])\n",
        "            z01[:,i-st0:i+st0,j-st0:j+st0] = model_output[0]\n",
        "    loss = torch.nn.functional.l1_loss(z00,ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(z00,ground_truth)\n",
        "    loss += torch.nn.functional.l1_loss(z01,z00)\n",
        "    loss += torch.nn.functional.mse_loss(z01,z00)\n",
        "    loss += torch.nn.functional.l1_loss(z01,ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(z01,ground_truth)\n",
        "    loss0 = torch.nn.functional.l1_loss(z01,ground_truth)\n",
        "    loss0 += torch.nn.functional.mse_loss(z01,ground_truth)\n",
        "\n",
        "    if step % 25 == 0:\n",
        "\n",
        "\n",
        "        print('Epoch %d, loss = %.06f' % (step, float(loss0)))\n",
        "        loss00.append(round(float(loss0),6))\n",
        "\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "model_params_list.append({'params':img_siren.parameters()})\n",
        "total_steps = 301\n",
        "for step in range(total_steps):\n",
        "\n",
        "    model_output2, h = img_siren(model_input2)\n",
        "    loss = torch.nn.functional.l1_loss(model_output2[0],ground_truth)\n",
        "    loss += torch.nn.functional.mse_loss(model_output2[0],ground_truth)\n",
        "\n",
        "    if step % 25 == 0:\n",
        "\n",
        "        print('Epoch %d, loss = %.06f' % (step, float(loss)))\n",
        "        loss00.append(round(float(loss),6))\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "loss00 = np.array(loss00)\n",
        "\n",
        "np.save('./{n}/loss_new_0_60_0.npy'.format(n = n), loss00)\n",
        "torch.save(img_siren.state_dict(), './{n}/best-model-img00.pt'.format(n = n))\n",
        "\n",
        "###\n",
        "\n",
        "# loading pre-trained MLP images generator with the best parameters obtained in the previous step\n",
        "\n",
        "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
        "                        hidden_layers=4, outermost_linear=True).cuda()\n",
        "img_siren.load_state_dict(torch.load('./{n}/best-model-img00.pt'.format(n = n)))\n",
        "img_siren.eval()\n",
        "###\n",
        "# load pre-trained MLP grid generator with initialized weights\n",
        "img_grid = conv_layers(2,2, num_hidden = 256, need_sigmoid = False, need_tanh = True)\n",
        "img_grid.cuda()\n",
        "img_grid.load_state_dict(torch.load('./best-model-grid02.pt'))\n",
        "img_grid.eval()\n",
        "###\n",
        "\n",
        "# creating a set of model parameters\n",
        "model_params_list = [{'params':img_grid.parameters()}]\n",
        "\n",
        "# training of MLP grid generator to compute xy displacement field\n",
        "\n",
        "optim = torch.optim.Adam(model_params_list, lr=1e-4)\n",
        "total_steps = 5001\n",
        "grid = []\n",
        "losses = []\n",
        "loss00 = []\n",
        "for step in range(total_steps):\n",
        "    h0 = img_grid(model_input2)\n",
        "    h1 = h0 + torch.randn_like(h0)*0.0005\n",
        "    h3 = 1.1*torch.cat([h0])\n",
        "    grid_output0 = 1.1*torch.cat([h1])\n",
        "    model_output0,w= img_siren(grid_output0)\n",
        "    loss = torch.nn.functional.l1_loss(model_output0[0][:,18:221,18:221],ground_truth1[:,18:221,18:221])\n",
        "    loss += torch.nn.functional.mse_loss(model_output0[0][:,18:221,18:221],ground_truth1[:,18:221,18:221])\n",
        "    if step % 25 == 0:\n",
        "        print('Epoch %d, loss = %.09f' % (step, float(loss)))\n",
        "        loss00.append(round(float(loss),6))\n",
        "    grid.append(h3)\n",
        "    losses.append(round(float(loss),9))\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "loss00 = np.array(loss00)\n",
        "np.save('./{n}/loss_new_1_60_0.npy'.format(n = n), loss00)\n",
        "###\n",
        "\n",
        "\n",
        "# convert and save displasement field to file new_60_0.npy\n",
        "ind = losses.index(min(losses))\n",
        "torch.save(grid[ind],'./{n}/tensor.pt'.format(n = n))\n",
        "refined_xy = torch.load('./{n}/tensor.pt'.format(n = n))\n",
        "z00 = torch.zeros(1,2,240,240).cuda()\n",
        "refined_warp = (refined_xy - xy_grid_batch_var2)\n",
        "\n",
        "refined_uv = torch.cat(((240 - 1.0)*refined_warp[:, 0:1, :, :]/2 , (240 - 1.0)*refined_warp[:, 1:2, :, :]/2), 1)\n",
        "\n",
        "warp_img = refined_uv[0].detach().cpu().numpy().transpose(1,2,0)\n",
        "z = np.zeros(shape = (240,240,2))\n",
        "\n",
        "np.save('./{n}/new_60_0.npy'.format(n = n), warp_img)\n",
        "###\n",
        "\n"
      ]
    }
  ]
}